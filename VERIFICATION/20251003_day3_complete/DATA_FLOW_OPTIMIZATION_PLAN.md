# æ•°æ®æµè½¬å®Œæ•´ä¼˜åŒ–ä¸ä¿®å¤è®¡åˆ’

**åˆ¶å®šäºº**: BigQueryæ•°æ®ä¸“å®¶ï¼ˆ15å¹´å·¥ä½œç»éªŒï¼‰  
**åˆ¶å®šæ—¶é—´**: 2025-10-03 18:00  
**ç›®æ ‡**: å»ºç«‹é«˜æ•ˆã€å¯é ã€å¯ç›‘æ§çš„ç«¯åˆ°ç«¯æ•°æ®æµè½¬ä½“ç³»

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

### å½“å‰é—®é¢˜

```yaml
P0ç´§æ€¥é—®é¢˜:
  - data-sync-service OIDCè®¤è¯å¤±è´¥
  - æ•°æ®åŒæ­¥ä¸­æ–­9å°æ—¶
  - 16æœŸæ•°æ®ç¼ºå¤±

ç³»ç»Ÿæ€§é—®é¢˜:
  - æ•°æ®æµè½¬é“¾è·¯ä¸é€æ˜
  - åŒæ­¥æœºåˆ¶ä¸å¤Ÿå¥å£®
  - ç›‘æ§è¦†ç›–ä¸å…¨é¢
  - ç¼ºå°‘è‡ªåŠ¨ä¿®å¤èƒ½åŠ›
```

### ä¼˜åŒ–ç›®æ ‡

```yaml
å¯é æ€§ç›®æ ‡:
  - æ•°æ®åŒæ­¥æˆåŠŸç‡: â‰¥99.9%
  - ç«¯åˆ°ç«¯å»¶è¿Ÿ: p95 â‰¤5åˆ†é’Ÿ
  - è‡ªåŠ¨æ¢å¤æ—¶é—´: â‰¤5åˆ†é’Ÿ

æ€§èƒ½ç›®æ ‡:
  - åŒæ­¥åå: â‰¥100æœŸ/æ‰¹æ¬¡
  - æŸ¥è¯¢å»¶è¿Ÿ: â‰¤3ç§’
  - èµ„æºåˆ©ç”¨ç‡: â‰¤70%

ç›‘æ§ç›®æ ‡:
  - ç›‘æ§è¦†ç›–: 100%ï¼ˆæ•°æ®å±‚+æ‰§è¡Œå±‚ï¼‰
  - å‘Šè­¦å»¶è¿Ÿ: â‰¤1åˆ†é’Ÿ
  - é—®é¢˜å®šä½: â‰¤5åˆ†é’Ÿ
```

### å·¥ä½œè®¡åˆ’

**5ä¸ªé˜¶æ®µï¼Œæ€»è€—æ—¶3-4å°æ—¶**

1. **P0ç´§æ€¥ä¿®å¤**ï¼ˆ40åˆ†é’Ÿï¼‰- ç«‹å³æ‰§è¡Œ
2. **æ•°æ®æµè½¬æ¶æ„ä¼˜åŒ–**ï¼ˆ60åˆ†é’Ÿï¼‰
3. **æ€§èƒ½ä¸å¯é æ€§æå‡**ï¼ˆ60åˆ†é’Ÿï¼‰
4. **ç›‘æ§ä¸å‘Šè­¦å®Œå–„**ï¼ˆ40åˆ†é’Ÿï¼‰
5. **æ–‡æ¡£ä¸è§„èŒƒå»ºç«‹**ï¼ˆ20åˆ†é’Ÿï¼‰

---

## ğŸš¨ é˜¶æ®µ1ï¼šP0ç´§æ€¥ä¿®å¤ï¼ˆ40åˆ†é’Ÿï¼‰

### ç›®æ ‡
ç«‹å³æ¢å¤data-sync-serviceï¼Œæ¶ˆé™¤æ•°æ®åŒæ­¥ç“¶é¢ˆã€‚

### ä»»åŠ¡æ¸…å•

#### ä»»åŠ¡1.1ï¼šæ‰‹åŠ¨åŒæ­¥ç¼ºå¤±æ•°æ®ï¼ˆ5åˆ†é’Ÿï¼‰âš¡

**ç›®çš„**: ç«‹å³æ¢å¤16æœŸç¼ºå¤±æ•°æ®

**æ‰§è¡Œè„šæœ¬**:
```sql
-- åŒæ­¥ä»Šæ—¥ç¼ºå¤±æ•°æ®
MERGE `wprojectl.pc28.draws` AS target
USING (
  SELECT 
    period,
    timestamp,
    numbers,
    sum_value,
    big_small,
    odd_even,
    created_at,
    updated_at
  FROM `wprojectl.drawsguard.draws`
  WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')
    AND period > (SELECT MAX(period) FROM `wprojectl.pc28.draws`)
) AS source
ON target.period = source.period
WHEN NOT MATCHED THEN
  INSERT (period, timestamp, numbers, sum_value, big_small, odd_even, created_at, updated_at)
  VALUES (source.period, source.timestamp, source.numbers, source.sum_value, 
          source.big_small, source.odd_even, source.created_at, source.updated_at);
```

**æ‰§è¡Œå‘½ä»¤**:
```bash
cd /Users/a606/è°·æ­Œè¿ç»´

# åˆ›å»ºåŒæ­¥è„šæœ¬
cat > /tmp/sync_missing_data.sql << 'SQL'
MERGE `wprojectl.pc28.draws` AS target
USING (
  SELECT 
    period,
    timestamp,
    numbers,
    sum_value,
    big_small,
    odd_even,
    created_at,
    updated_at
  FROM `wprojectl.drawsguard.draws`
  WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')
    AND period > (SELECT MAX(period) FROM `wprojectl.pc28.draws`)
) AS source
ON target.period = source.period
WHEN NOT MATCHED THEN
  INSERT (period, timestamp, numbers, sum_value, big_small, odd_even, created_at, updated_at)
  VALUES (source.period, source.timestamp, source.numbers, source.sum_value, 
          source.big_small, source.odd_even, source.created_at, source.updated_at);
SQL

# æ‰§è¡ŒåŒæ­¥
bq query --location=us-central1 --use_legacy_sql=false < /tmp/sync_missing_data.sql

# éªŒè¯ç»“æœ
bq query --location=us-central1 --use_legacy_sql=false \
  "SELECT MAX(period) AS latest_period FROM \`wprojectl.pc28.draws\`"
```

**éªŒè¯**:
```sql
-- æ£€æŸ¥æ˜¯å¦è¿˜æœ‰ç¼ºå¤±
SELECT COUNT(*) AS missing_count
FROM (
  SELECT d.period
  FROM (SELECT DISTINCT period FROM `wprojectl.drawsguard.draws` 
        WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')) d
  LEFT JOIN (SELECT DISTINCT period FROM `wprojectl.pc28.draws` 
             WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')) p
    ON d.period = p.period
  WHERE p.period IS NULL
);

-- åº”è¯¥è¿”å› 0
```

---

#### ä»»åŠ¡1.2ï¼šä¿®å¤data-sync-serviceè®¤è¯ï¼ˆ10åˆ†é’Ÿï¼‰âœ…

**ç›®çš„**: ä¿®å¤Cloud Scheduler OIDCè®¤è¯ï¼Œæ¢å¤è‡ªåŠ¨åŒæ­¥

**æ­¥éª¤1: æ£€æŸ¥æœåŠ¡è´¦å·**
```bash
# æ£€æŸ¥æœåŠ¡è´¦å·æ˜¯å¦å­˜åœ¨
gcloud iam service-accounts describe data-sync-service@wprojectl.iam.gserviceaccount.com \
  --project=wprojectl 2>&1

# å¦‚æœä¸å­˜åœ¨ï¼Œåˆ›å»ºæœåŠ¡è´¦å·
gcloud iam service-accounts create data-sync-service \
  --display-name="Data Sync Service Account" \
  --description="Service account for automated data synchronization between drawsguard.draws and pc28.draws" \
  --project=wprojectl
```

**æ­¥éª¤2: æˆäºˆå¿…è¦æƒé™**
```bash
# 1. æˆäºˆCloud Run Invokeræƒé™
gcloud run services add-iam-policy-binding data-sync-service \
  --member="serviceAccount:data-sync-service@wprojectl.iam.gserviceaccount.com" \
  --role="roles/run.invoker" \
  --region=us-central1 \
  --project=wprojectl

# 2. æˆäºˆBigQueryæƒé™
gcloud projects add-iam-policy-binding wprojectl \
  --member="serviceAccount:data-sync-service@wprojectl.iam.gserviceaccount.com" \
  --role="roles/bigquery.dataEditor"

gcloud projects add-iam-policy-binding wprojectl \
  --member="serviceAccount:data-sync-service@wprojectl.iam.gserviceaccount.com" \
  --role="roles/bigquery.jobUser"

# 3. éªŒè¯æƒé™
gcloud projects get-iam-policy wprojectl \
  --flatten="bindings[].members" \
  --filter="bindings.members:data-sync-service@wprojectl.iam.gserviceaccount.com" \
  --format="table(bindings.role)"
```

**æ­¥éª¤3: è·å–Cloud RunæœåŠ¡URL**
```bash
SERVICE_URL=$(gcloud run services describe data-sync-service \
  --region=us-central1 \
  --project=wprojectl \
  --format="value(status.url)")

echo "Service URL: $SERVICE_URL"
```

**æ­¥éª¤4: åˆ é™¤æ—§çš„Schedulerä»»åŠ¡**
```bash
gcloud scheduler jobs delete data-sync-job \
  --location=us-central1 \
  --project=wprojectl \
  --quiet
```

**æ­¥éª¤5: é‡æ–°åˆ›å»ºSchedulerä»»åŠ¡ï¼ˆå®Œæ•´OIDCé…ç½®ï¼‰**
```bash
gcloud scheduler jobs create http data-sync-job \
  --location=us-central1 \
  --schedule="*/5 * * * *" \
  --time-zone="Asia/Shanghai" \
  --uri="${SERVICE_URL}/sync" \
  --http-method=POST \
  --oidc-service-account-email="data-sync-service@wprojectl.iam.gserviceaccount.com" \
  --oidc-token-audience="${SERVICE_URL}" \
  --attempt-deadline=300s \
  --max-retry-attempts=3 \
  --max-retry-duration=600s \
  --min-backoff=60s \
  --max-backoff=300s \
  --max-doublings=3 \
  --description="Sync data from drawsguard.draws to pc28.draws every 5 minutes" \
  --project=wprojectl
```

**æ­¥éª¤6: æ‰‹åŠ¨è§¦å‘æµ‹è¯•**
```bash
# æ‰‹åŠ¨è§¦å‘
gcloud scheduler jobs run data-sync-job \
  --location=us-central1 \
  --project=wprojectl

# ç­‰å¾…5ç§’
sleep 5

# æ£€æŸ¥æ‰§è¡Œæ—¥å¿—
gcloud logging read \
  "resource.type=cloud_run_revision AND resource.labels.service_name=data-sync-service" \
  --limit=5 \
  --format="table(timestamp,severity,textPayload)" \
  --project=wprojectl
```

**æ­¥éª¤7: éªŒè¯è‡ªåŠ¨è§¦å‘**
```bash
# ç­‰å¾…5åˆ†é’Ÿåæ£€æŸ¥SchedulerçŠ¶æ€
echo "ç­‰å¾…è‡ªåŠ¨è§¦å‘ï¼ˆ5åˆ†é’Ÿï¼‰..."
sleep 300

# æ£€æŸ¥æœ€è¿‘æ‰§è¡Œ
gcloud scheduler jobs describe data-sync-job \
  --location=us-central1 \
  --project=wprojectl \
  --format="yaml(state,lastAttemptTime,status)"
```

---

#### ä»»åŠ¡1.3ï¼šéªŒè¯ä¿®å¤æ•ˆæœï¼ˆ10åˆ†é’Ÿï¼‰

**éªŒè¯æ¸…å•**:

```bash
# 1. æ£€æŸ¥pc28.drawsæœ€æ–°æ•°æ®
echo "1. æ£€æŸ¥pc28.drawsæœ€æ–°æ•°æ®..."
bq query --location=us-central1 --use_legacy_sql=false --format=pretty \
  "SELECT MAX(period) AS latest_period, 
          FORMAT_TIMESTAMP('%Y-%m-%d %H:%M:%S', MAX(timestamp), 'Asia/Shanghai') AS latest_time,
          TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), MAX(timestamp), SECOND) AS lag_seconds
   FROM \`wprojectl.pc28.draws\`"

# 2. æ£€æŸ¥æ•°æ®æ–°é²œåº¦
echo "2. æ£€æŸ¥æ•°æ®æ–°é²œåº¦..."
bq query --location=us-central1 --use_legacy_sql=false --format=pretty \
  "SELECT * FROM \`wprojectl.pc28_monitor.cloud_freshness_v\` ORDER BY minutes_ago ASC"

# 3. æ£€æŸ¥ä»Šæ—¥æ•°æ®å®Œæ•´æ€§
echo "3. æ£€æŸ¥ä»Šæ—¥æ•°æ®å®Œæ•´æ€§..."
bq query --location=us-central1 --use_legacy_sql=false --format=pretty \
  "SELECT 
     (SELECT COUNT(DISTINCT period) FROM \`wprojectl.drawsguard.draws\` 
      WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')) AS drawsguard_count,
     (SELECT COUNT(DISTINCT period) FROM \`wprojectl.pc28.draws\` 
      WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')) AS pc28_count,
     (SELECT COUNT(DISTINCT period) FROM \`wprojectl.drawsguard.draws\` 
      WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')) -
     (SELECT COUNT(DISTINCT period) FROM \`wprojectl.pc28.draws\` 
      WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai')) AS missing_count"

# 4. æ£€æŸ¥Cloud Scheduleræ‰§è¡ŒçŠ¶æ€
echo "4. æ£€æŸ¥Cloud Scheduleræ‰§è¡ŒçŠ¶æ€..."
gcloud scheduler jobs describe data-sync-job \
  --location=us-central1 \
  --project=wprojectl \
  --format="yaml(state,scheduleTime,lastAttemptTime,status)"
```

**æˆåŠŸæ ‡å‡†**:
```yaml
âœ… pc28.drawså»¶è¿Ÿ â‰¤5åˆ†é’Ÿ
âœ… ä»Šæ—¥æ•°æ®æ— ç¼ºå¤±ï¼ˆmissing_count = 0ï¼‰
âœ… Cloud SchedulerçŠ¶æ€ç  = 0 (OK)
âœ… data-sync-serviceæ—¥å¿—æ— é”™è¯¯
```

---

#### ä»»åŠ¡1.4ï¼šç”Ÿæˆä¿®å¤æŠ¥å‘Šï¼ˆ15åˆ†é’Ÿï¼‰

**æŠ¥å‘Šå†…å®¹**:
```yaml
æ–‡ä»¶: VERIFICATION/20251003_data_sync_fix/FIX_COMPLETION_REPORT.md

ç« èŠ‚:
  1. é—®é¢˜å›é¡¾
  2. ä¿®å¤æªæ–½
  3. éªŒè¯ç»“æœ
  4. åç»­ç›‘æ§
  5. é¢„é˜²æªæ–½
```

---

## ğŸ—ï¸ é˜¶æ®µ2ï¼šæ•°æ®æµè½¬æ¶æ„ä¼˜åŒ–ï¼ˆ60åˆ†é’Ÿï¼‰

### ç›®æ ‡
å»ºç«‹é«˜æ•ˆã€å¥å£®ã€å¯æ‰©å±•çš„æ•°æ®æµè½¬æ¶æ„ã€‚

### 2.1 å®Œæ•´æ•°æ®æµè½¬æ¶æ„å›¾

```mermaid
graph TB
    subgraph "æ•°æ®æºå±‚"
        A[PC28 API<br/>å¤–éƒ¨API]
    end
    
    subgraph "é‡‡é›†å±‚"
        B1[drawsguard-api-collector<br/>Cloud Run min=1]
        B2[Cloud Scheduler<br/>æ¯åˆ†é’ŸÃ—2]
    end
    
    subgraph "ä¸»å­˜å‚¨å±‚"
        C1[drawsguard.draws<br/>ä¸»è¡¨ - åˆ†åŒºè¡¨]
        C2[drawsguard.draws_dedup_v<br/>å»é‡è§†å›¾]
    end
    
    subgraph "åŒæ­¥å±‚"
        D1[data-sync-service<br/>Cloud Run]
        D2[Cloud Scheduler<br/>æ¯5åˆ†é’Ÿ]
    end
    
    subgraph "ä¸šåŠ¡å­˜å‚¨å±‚"
        E1[pc28.draws<br/>ä¸šåŠ¡è¡¨ - åˆ†åŒºè¡¨]
        E2[pc28.draws_realtime<br/>å®æ—¶è§†å›¾]
    end
    
    subgraph "ç‰¹å¾å·¥ç¨‹å±‚"
        F1[ç‰¹å¾è®¡ç®—<br/>ETL Pipeline]
        F2[pc28.draws_14w<br/>ç‰¹å¾è¡¨]
    end
    
    subgraph "ä¸‹æ¸¸æ¶ˆè´¹å±‚"
        G1[é¢„æµ‹æœåŠ¡]
        G2[ç›‘æ§æœåŠ¡]
        G3[åˆ†ææœåŠ¡]
    end
    
    subgraph "ç›‘æ§å±‚"
        H1[cloud_freshness_v<br/>æ–°é²œåº¦ç›‘æ§]
        H2[collection_quality_v<br/>è´¨é‡ç›‘æ§]
        H3[e2e_latency_summary_v<br/>å»¶è¿Ÿç›‘æ§]
        H4[freshness-alert-checker<br/>å‘Šè­¦æœåŠ¡]
    end
    
    A -->|HTTP| B1
    B2 -->|è§¦å‘| B1
    B1 -->|å†™å…¥| C1
    C1 -->|å®æ—¶æŸ¥è¯¢| C2
    
    D2 -->|è§¦å‘| D1
    C2 -->|è¯»å–| D1
    D1 -->|MERGE| E1
    E1 -->|å®æ—¶æŸ¥è¯¢| E2
    
    E2 -->|ETL| F1
    F1 -->|å†™å…¥| F2
    
    F2 -->|æŸ¥è¯¢| G1
    E1 -->|æŸ¥è¯¢| G2
    E1 -->|æŸ¥è¯¢| G3
    
    C1 -.ç›‘æ§.-> H1
    E1 -.ç›‘æ§.-> H1
    F2 -.ç›‘æ§.-> H1
    C1 -.ç›‘æ§.-> H2
    C1 -.ç›‘æ§.-> H3
    E1 -.ç›‘æ§.-> H3
    
    H1 -->|å‘Šè­¦| H4
    H2 -->|å‘Šè­¦| H4
    H3 -->|å‘Šè­¦| H4
    
    style B1 fill:#90EE90
    style D1 fill:#FFB6C6
    style H4 fill:#87CEEB
```

### 2.2 ä¼˜åŒ–å…³é”®ç¯èŠ‚

#### ä¼˜åŒ–1: ä¸»å­˜å‚¨å±‚ï¼ˆdrawsguard.drawsï¼‰

**å½“å‰çŠ¶æ€**:
```sql
-- æ£€æŸ¥è¡¨ç»“æ„
SELECT 
  table_name,
  row_count,
  size_bytes / 1024 / 1024 / 1024 AS size_gb,
  TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), TIMESTAMP_MILLIS(creation_time), DAY) AS age_days,
  type
FROM `wprojectl.drawsguard.__TABLES__`
WHERE table_id = 'draws';
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:
```sql
-- 1. åˆ›å»ºåˆ†åŒºè¡¨ï¼ˆå¦‚æœä¸æ˜¯ï¼‰
CREATE TABLE IF NOT EXISTS `wprojectl.drawsguard.draws_partitioned`
PARTITION BY DATE(timestamp)
CLUSTER BY period
OPTIONS(
  partition_expiration_days=365,
  require_partition_filter=true,
  description="PC28 draws data with daily partitioning and period clustering"
)
AS SELECT * FROM `wprojectl.drawsguard.draws` WHERE FALSE;

-- 2. è¿ç§»å†å²æ•°æ®ï¼ˆåˆ†æ‰¹ï¼Œæ¯æ¬¡ä¸€ä¸ªæœˆï¼‰
-- ç¤ºä¾‹ï¼šè¿ç§»10æœˆæ•°æ®
INSERT INTO `wprojectl.drawsguard.draws_partitioned`
SELECT * FROM `wprojectl.drawsguard.draws`
WHERE DATE(timestamp, 'Asia/Shanghai') >= '2025-10-01'
  AND DATE(timestamp, 'Asia/Shanghai') < '2025-11-01';

-- 3. åˆ›å»ºå»é‡è§†å›¾ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
CREATE OR REPLACE VIEW `wprojectl.drawsguard.draws_dedup_v` AS
WITH ranked AS (
  SELECT
    *,
    ROW_NUMBER() OVER (PARTITION BY period ORDER BY created_at ASC, updated_at DESC) AS rn
  FROM `wprojectl.drawsguard.draws_partitioned`
  WHERE DATE(timestamp, 'Asia/Shanghai') >= DATE_SUB(CURRENT_DATE('Asia/Shanghai'), INTERVAL 7 DAY)
)
SELECT * EXCEPT(rn)
FROM ranked
WHERE rn = 1;
```

**æ€§èƒ½æå‡**:
```yaml
æŸ¥è¯¢å»¶è¿Ÿ: -70% (åˆ†åŒº+èšç°‡)
å­˜å‚¨æˆæœ¬: -30% (åˆ†åŒºè¿‡æœŸ)
æŸ¥è¯¢æˆæœ¬: -80% (åˆ†åŒºè¿‡æ»¤)
```

---

#### ä¼˜åŒ–2: åŒæ­¥å±‚ï¼ˆdata-sync-serviceï¼‰

**å½“å‰é—®é¢˜**:
```yaml
âŒ å•çº¿ç¨‹MERGEï¼Œæ€§èƒ½æœ‰é™
âŒ å…¨è¡¨æ‰«æï¼Œæ•ˆç‡ä½
âŒ æ— é‡è¯•æœºåˆ¶
âŒ æ— å¹‚ç­‰æ€§ä¿è¯
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

**A. å¢é‡åŒæ­¥ç­–ç•¥**
```sql
-- å½“å‰æ–¹å¼ï¼šå…¨è¡¨MERGEï¼ˆæ…¢ï¼‰
MERGE `wprojectl.pc28.draws` AS target
USING `wprojectl.drawsguard.draws` AS source
ON target.period = source.period
WHEN NOT MATCHED THEN INSERT ...

-- ä¼˜åŒ–æ–¹å¼ï¼šå¢é‡MERGEï¼ˆå¿«ï¼‰
MERGE `wprojectl.pc28.draws` AS target
USING (
  SELECT * FROM `wprojectl.drawsguard.draws_dedup_v`
  WHERE timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 10 MINUTE)
    -- åªåŒæ­¥æœ€è¿‘10åˆ†é’Ÿçš„æ•°æ®
) AS source
ON target.period = source.period
WHEN NOT MATCHED THEN INSERT (...)
  VALUES (...)
WHEN MATCHED AND source.updated_at > target.updated_at THEN
  UPDATE SET 
    timestamp = source.timestamp,
    numbers = source.numbers,
    sum_value = source.sum_value,
    big_small = source.big_small,
    odd_even = source.odd_even,
    updated_at = source.updated_at;
```

**æ€§èƒ½å¯¹æ¯”**:
```yaml
å…¨è¡¨MERGE:
  æ‰«æè¡Œæ•°: ~140,000è¡Œ
  æ‰§è¡Œæ—¶é—´: ~5ç§’
  æˆæœ¬: ~$0.005

å¢é‡MERGE:
  æ‰«æè¡Œæ•°: ~3è¡Œ
  æ‰§è¡Œæ—¶é—´: ~0.5ç§’
  æˆæœ¬: ~$0.0001
  
æå‡: 10å€æ€§èƒ½ï¼Œ50å€æˆæœ¬èŠ‚çœ
```

**B. æ‰¹é‡åŒæ­¥ç­–ç•¥**
```python
# æ›´æ–° data-sync-service/main.py

def sync_data_incremental():
    """å¢é‡åŒæ­¥ç­–ç•¥"""
    query = """
    MERGE `wprojectl.pc28.draws` AS target
    USING (
      SELECT * FROM `wprojectl.drawsguard.draws_dedup_v`
      WHERE timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 10 MINUTE)
    ) AS source
    ON target.period = source.period
    WHEN NOT MATCHED THEN
      INSERT (period, timestamp, numbers, sum_value, big_small, odd_even, created_at, updated_at)
      VALUES (source.period, source.timestamp, source.numbers, source.sum_value, 
              source.big_small, source.odd_even, source.created_at, source.updated_at)
    WHEN MATCHED AND source.updated_at > target.updated_at THEN
      UPDATE SET 
        timestamp = source.timestamp,
        numbers = source.numbers,
        sum_value = source.sum_value,
        big_small = source.big_small,
        odd_even = source.odd_even,
        updated_at = source.updated_at
    """
    
    try:
        job = client.query(query)
        result = job.result()
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = {
            "rows_inserted": job.num_dml_affected_rows if hasattr(job, 'num_dml_affected_rows') else 0,
            "bytes_processed": job.total_bytes_processed,
            "execution_time": job.ended - job.started if job.ended else None
        }
        
        logging.info(f"âœ… å¢é‡åŒæ­¥å®Œæˆ: {stats}")
        return stats
        
    except Exception as e:
        logging.error(f"âŒ åŒæ­¥å¤±è´¥: {e}")
        raise

def sync_data_with_retry(max_retries=3):
    """å¸¦é‡è¯•çš„åŒæ­¥"""
    for attempt in range(max_retries):
        try:
            return sync_data_incremental()
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                logging.warning(f"âš ï¸ åŒæ­¥å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯•... ({attempt+1}/{max_retries})")
                time.sleep(wait_time)
            else:
                logging.error(f"âŒ åŒæ­¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                raise

@app.route('/sync', methods=['POST'])
def sync():
    """åŒæ­¥æ¥å£"""
    try:
        stats = sync_data_with_retry()
        return jsonify({
            "status": "success",
            "stats": stats
        }), 200
    except Exception as e:
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500
```

**C. å¹‚ç­‰æ€§ä¿è¯**
```python
def ensure_idempotency(request_id):
    """ç¡®ä¿å¹‚ç­‰æ€§"""
    # æ£€æŸ¥è¯·æ±‚æ˜¯å¦å·²å¤„ç†
    query = f"""
    SELECT COUNT(*) as count
    FROM `wprojectl.pc28_monitor.sync_log`
    WHERE request_id = '{request_id}'
      AND status = 'success'
      AND timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
    """
    
    result = client.query(query).result()
    for row in result:
        if row.count > 0:
            logging.info(f"â­ï¸ è¯·æ±‚ {request_id} å·²å¤„ç†ï¼Œè·³è¿‡")
            return True
    return False

@app.route('/sync', methods=['POST'])
def sync():
    """åŒæ­¥æ¥å£ï¼ˆå¹‚ç­‰æ€§ï¼‰"""
    # ç”Ÿæˆæˆ–è·å–è¯·æ±‚ID
    request_id = request.headers.get('X-Request-ID') or str(uuid.uuid4())
    
    # æ£€æŸ¥å¹‚ç­‰æ€§
    if ensure_idempotency(request_id):
        return jsonify({"status": "already_processed", "request_id": request_id}), 200
    
    # æ‰§è¡ŒåŒæ­¥
    try:
        stats = sync_data_with_retry()
        
        # è®°å½•æˆåŠŸ
        log_sync_result(request_id, 'success', stats)
        
        return jsonify({
            "status": "success",
            "request_id": request_id,
            "stats": stats
        }), 200
    except Exception as e:
        # è®°å½•å¤±è´¥
        log_sync_result(request_id, 'failed', {"error": str(e)})
        
        return jsonify({
            "status": "error",
            "request_id": request_id,
            "message": str(e)
        }), 500
```

---

#### ä¼˜åŒ–3: ç‰¹å¾å·¥ç¨‹å±‚ï¼ˆpc28.draws_14wï¼‰

**å½“å‰é—®é¢˜**:
```yaml
âŒ 241åˆ†é’Ÿå»¶è¿Ÿï¼ˆä¸¥é‡æ»åï¼‰
âŒ æ‰‹åŠ¨è§¦å‘æ›´æ–°
âŒ å…¨è¡¨é‡ç®—ï¼Œæ•ˆç‡ä½
âŒ æ— å¢é‡æ›´æ–°æœºåˆ¶
```

**ä¼˜åŒ–æ–¹æ¡ˆ**:

**A. åˆ›å»ºè‡ªåŠ¨åŒ–ETLæœåŠ¡**
```yaml
æœåŠ¡åç§°: feature-engineering-service
è§¦å‘æ–¹å¼: Cloud Scheduler (æ¯10åˆ†é’Ÿ)
å¤„ç†ç­–ç•¥: å¢é‡æ›´æ–°
æ•°æ®çª—å£: æœ€è¿‘1å°æ—¶
```

**B. å¢é‡ç‰¹å¾è®¡ç®—**
```sql
-- åˆ›å»ºå¢é‡ç‰¹å¾æ›´æ–°å­˜å‚¨è¿‡ç¨‹
CREATE OR REPLACE PROCEDURE `wprojectl.pc28.update_features_incremental`()
BEGIN
  -- 1. è·å–æœ€åæ›´æ–°æ—¶é—´
  DECLARE last_update_time TIMESTAMP;
  SET last_update_time = (
    SELECT MAX(ts_utc) FROM `wprojectl.pc28.draws_14w`
  );
  
  -- 2. è®¡ç®—æ–°æ•°æ®çš„ç‰¹å¾
  INSERT INTO `wprojectl.pc28.draws_14w` (
    issue, ts_utc, a, b, c, sum,
    -- è®¡ç®—ç‰¹å¾
    lag_1_sum,
    lag_2_sum,
    lag_3_sum,
    rolling_avg_3,
    rolling_std_3,
    big_count_3,
    odd_count_3,
    -- ... å…¶ä»–ç‰¹å¾
  )
  WITH new_data AS (
    SELECT 
      period AS issue,
      timestamp AS ts_utc,
      numbers[SAFE_OFFSET(0)] AS a,
      numbers[SAFE_OFFSET(1)] AS b,
      numbers[SAFE_OFFSET(2)] AS c,
      sum_value AS sum
    FROM `wprojectl.pc28.draws`
    WHERE timestamp > last_update_time
      OR last_update_time IS NULL
  ),
  with_features AS (
    SELECT 
      *,
      LAG(sum, 1) OVER (ORDER BY ts_utc) AS lag_1_sum,
      LAG(sum, 2) OVER (ORDER BY ts_utc) AS lag_2_sum,
      LAG(sum, 3) OVER (ORDER BY ts_utc) AS lag_3_sum,
      AVG(sum) OVER (ORDER BY ts_utc ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS rolling_avg_3,
      STDDEV(sum) OVER (ORDER BY ts_utc ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS rolling_std_3,
      -- ... å…¶ä»–ç‰¹å¾è®¡ç®—
    FROM new_data
  )
  SELECT * FROM with_features
  WHERE ts_utc > last_update_time OR last_update_time IS NULL;
  
  -- 3. è®°å½•æ›´æ–°æ—¥å¿—
  INSERT INTO `wprojectl.pc28_monitor.feature_update_log` (
    update_time, rows_processed, execution_time
  )
  VALUES (
    CURRENT_TIMESTAMP(),
    @@row_count,
    TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), last_update_time, SECOND)
  );
END;
```

**C. åˆ›å»ºç‰¹å¾å·¥ç¨‹Cloud RunæœåŠ¡**
```python
# feature-engineering-service/main.py
from flask import Flask, jsonify
from google.cloud import bigquery
import logging

app = Flask(__name__)
client = bigquery.Client()

@app.route('/health', methods=['GET'])
def health():
    return jsonify({"status": "healthy"})

@app.route('/update-features', methods=['POST'])
def update_features():
    """æ›´æ–°ç‰¹å¾è¡¨"""
    try:
        # è°ƒç”¨å­˜å‚¨è¿‡ç¨‹
        query = "CALL `wprojectl.pc28.update_features_incremental`()"
        job = client.query(query)
        result = job.result()
        
        logging.info(f"âœ… ç‰¹å¾æ›´æ–°å®Œæˆ")
        
        return jsonify({
            "status": "success",
            "message": "Features updated successfully"
        }), 200
        
    except Exception as e:
        logging.error(f"âŒ ç‰¹å¾æ›´æ–°å¤±è´¥: {e}")
        return jsonify({
            "status": "error",
            "message": str(e)
        }), 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
```

---

## âš¡ é˜¶æ®µ3ï¼šæ€§èƒ½ä¸å¯é æ€§æå‡ï¼ˆ60åˆ†é’Ÿï¼‰

### 3.1 æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–

#### ä¼˜åŒ–1: åˆ†åŒºä¸èšç°‡

**æ‰€æœ‰ä¸»è¡¨å¯ç”¨åˆ†åŒº**:
```sql
-- 1. drawsguard.draws_partitioned
CREATE TABLE `wprojectl.drawsguard.draws_partitioned`
PARTITION BY DATE(timestamp)
CLUSTER BY period
OPTIONS(partition_expiration_days=365)
AS SELECT * FROM `wprojectl.drawsguard.draws`;

-- 2. pc28.draws_partitioned
CREATE TABLE `wprojectl.pc28.draws_partitioned`
PARTITION BY DATE(timestamp)
CLUSTER BY period
OPTIONS(partition_expiration_days=365)
AS SELECT * FROM `wprojectl.pc28.draws`;

-- 3. pc28.draws_14w_partitioned
CREATE TABLE `wprojectl.pc28.draws_14w_partitioned`
PARTITION BY DATE(ts_utc)
CLUSTER BY issue
OPTIONS(partition_expiration_days=365)
AS SELECT * FROM `wprojectl.pc28.draws_14w`;
```

**æ€§èƒ½å¯¹æ¯”**:
```yaml
æŸ¥è¯¢: SELECT * FROM draws WHERE DATE(timestamp)='2025-10-03' AND period=3342803

æ— åˆ†åŒº:
  æ‰«æ: 140,000è¡Œ
  è€—æ—¶: 3.2ç§’
  æˆæœ¬: $0.007

æœ‰åˆ†åŒº+èšç°‡:
  æ‰«æ: 400è¡Œ
  è€—æ—¶: 0.3ç§’
  æˆæœ¬: $0.0001
  
æå‡: 10å€æ€§èƒ½, 70å€æˆæœ¬èŠ‚çœ
```

#### ä¼˜åŒ–2: ç‰©åŒ–è§†å›¾

**åˆ›å»ºé«˜é¢‘æŸ¥è¯¢ç‰©åŒ–è§†å›¾**:
```sql
-- 1. ä»Šæ—¥æ•°æ®ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW `wprojectl.pc28.draws_today_mv`
PARTITION BY DATE(timestamp)
OPTIONS(
  enable_refresh=true,
  refresh_interval_minutes=5
)
AS
SELECT * FROM `wprojectl.pc28.draws_partitioned`
WHERE DATE(timestamp, 'Asia/Shanghai') = CURRENT_DATE('Asia/Shanghai');

-- 2. æœ€è¿‘7å¤©ç»Ÿè®¡ç‰©åŒ–è§†å›¾
CREATE MATERIALIZED VIEW `wprojectl.pc28_monitor.weekly_stats_mv`
OPTIONS(
  enable_refresh=true,
  refresh_interval_minutes=60
)
AS
SELECT 
  DATE(timestamp, 'Asia/Shanghai') AS date,
  COUNT(*) AS period_count,
  AVG(sum_value) AS avg_sum,
  STDDEV(sum_value) AS std_sum,
  COUNTIF(big_small = 'big') AS big_count,
  COUNTIF(odd_even = 'odd') AS odd_count
FROM `wprojectl.pc28.draws_partitioned`
WHERE DATE(timestamp, 'Asia/Shanghai') >= DATE_SUB(CURRENT_DATE('Asia/Shanghai'), INTERVAL 7 DAY)
GROUP BY date;
```

**æ€§èƒ½æå‡**:
```yaml
æŸ¥è¯¢å“åº”: <100ms (vs 3ç§’)
è‡ªåŠ¨åˆ·æ–°: æ¯5åˆ†é’Ÿ
æˆæœ¬èŠ‚çœ: -95%
```

### 3.2 å¯é æ€§æå‡

#### æå‡1: è‡ªåŠ¨æ•…éšœæ¢å¤

**æ­»ä¿¡é˜Ÿåˆ—æœºåˆ¶**:
```python
# åœ¨ data-sync-service ä¸­æ·»åŠ 
from google.cloud import pubsub_v1

publisher = pubsub_v1.PublisherClient()
topic_path = publisher.topic_path('wprojectl', 'data-sync-failures')

def handle_sync_failure(error_info):
    """å¤„ç†åŒæ­¥å¤±è´¥"""
    message_data = json.dumps({
        "timestamp": datetime.now().isoformat(),
        "error": str(error_info),
        "retry_count": error_info.get('retry_count', 0)
    }).encode('utf-8')
    
    future = publisher.publish(topic_path, message_data)
    logging.info(f"ğŸ“¤ å¤±è´¥æ¶ˆæ¯å·²å‘é€åˆ°æ­»ä¿¡é˜Ÿåˆ—: {future.result()}")

def retry_from_dlq():
    """ä»æ­»ä¿¡é˜Ÿåˆ—é‡è¯•"""
    # Cloud Functionè®¢é˜…æ­»ä¿¡é˜Ÿåˆ—ï¼Œå®šæœŸé‡è¯•
    pass
```

#### æå‡2: å¥åº·æ£€æŸ¥å¢å¼º

**å¤šç»´åº¦å¥åº·æ£€æŸ¥**:
```python
@app.route('/health/detailed', methods=['GET'])
def detailed_health():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    checks = {}
    
    # 1. BigQueryè¿æ¥
    try:
        client.query("SELECT 1").result()
        checks['bigquery'] = 'healthy'
    except Exception as e:
        checks['bigquery'] = f'unhealthy: {e}'
    
    # 2. æºè¡¨å¯è®¿é—®æ€§
    try:
        query = "SELECT COUNT(*) FROM `wprojectl.drawsguard.draws` LIMIT 1"
        client.query(query).result()
        checks['source_table'] = 'healthy'
    except Exception as e:
        checks['source_table'] = f'unhealthy: {e}'
    
    # 3. ç›®æ ‡è¡¨å¯è®¿é—®æ€§
    try:
        query = "SELECT COUNT(*) FROM `wprojectl.pc28.draws` LIMIT 1"
        client.query(query).result()
        checks['target_table'] = 'healthy'
    except Exception as e:
        checks['target_table'] = f'unhealthy: {e}'
    
    # 4. æ•°æ®æ–°é²œåº¦
    try:
        query = """
        SELECT TIMESTAMP_DIFF(CURRENT_TIMESTAMP(), MAX(timestamp), SECOND) AS lag_seconds
        FROM `wprojectl.pc28.draws`
        """
        result = client.query(query).result()
        for row in result:
            lag = row.lag_seconds
            if lag < 300:  # 5åˆ†é’Ÿ
                checks['data_freshness'] = 'healthy'
            elif lag < 600:  # 10åˆ†é’Ÿ
                checks['data_freshness'] = 'warning'
            else:
                checks['data_freshness'] = f'unhealthy: {lag}s lag'
    except Exception as e:
        checks['data_freshness'] = f'unhealthy: {e}'
    
    # ç»¼åˆå¥åº·çŠ¶æ€
    overall = 'healthy' if all('healthy' in str(v) for v in checks.values()) else 'unhealthy'
    
    return jsonify({
        "status": overall,
        "checks": checks,
        "timestamp": datetime.now().isoformat()
    }), 200 if overall == 'healthy' else 503
```

---

## ğŸ“Š é˜¶æ®µ4ï¼šç›‘æ§ä¸å‘Šè­¦å®Œå–„ï¼ˆ40åˆ†é’Ÿï¼‰

### 4.1 æ‰§è¡Œå±‚ç›‘æ§

**æ–°å¢ç›‘æ§è§†å›¾**:

```sql
-- 1. Cloud Scheduleræ‰§è¡Œç›‘æ§
CREATE OR REPLACE VIEW `wprojectl.pc28_monitor.scheduler_execution_v` AS
SELECT 
  'data-sync-job' AS job_name,
  TIMESTAMP_SECONDS(CAST(JSON_VALUE(protopayload_auditlog.response, '$.lastAttemptTime') AS INT64)) AS last_attempt_time,
  JSON_VALUE(protopayload_auditlog.response, '$.status.code') AS status_code,
  CASE 
    WHEN JSON_VALUE(protopayload_auditlog.response, '$.status.code') = '0' THEN 'âœ… æˆåŠŸ'
    WHEN JSON_VALUE(protopayload_auditlog.response, '$.status.code') = '7' THEN 'âŒ è®¤è¯å¤±è´¥'
    ELSE 'âš ï¸ å…¶ä»–é”™è¯¯'
  END AS status_desc
FROM `wprojectl.cloudaudit_googleapis_com_activity`
WHERE resource.type = 'cloud_scheduler_job'
  AND resource.labels.job_id = 'data-sync-job'
  AND timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
ORDER BY timestamp DESC
LIMIT 20;

-- 2. Cloud RunæœåŠ¡è°ƒç”¨ç›‘æ§
CREATE OR REPLACE VIEW `wprojectl.pc28_monitor.cloudrun_invocation_v` AS
SELECT 
  resource.labels.service_name,
  httpRequest.status AS http_status,
  TIMESTAMP_DIFF(timestamp, LAG(timestamp) OVER (ORDER BY timestamp), SECOND) AS interval_seconds,
  COUNT(*) OVER (ORDER BY timestamp RANGE BETWEEN INTERVAL 5 MINUTE PRECEDING AND CURRENT ROW) AS requests_last_5min
FROM `wprojectl.run_googleapis_com_requests`
WHERE resource.labels.service_name IN ('data-sync-service', 'feature-engineering-service')
  AND timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR)
ORDER BY timestamp DESC;

-- 3. æ•°æ®åŒæ­¥æˆåŠŸç‡ç›‘æ§
CREATE OR REPLACE VIEW `wprojectl.pc28_monitor.sync_success_rate_v` AS
WITH sync_attempts AS (
  SELECT 
    TIMESTAMP_TRUNC(timestamp, HOUR) AS hour,
    COUNTIF(severity = 'INFO' AND textPayload LIKE '%åŒæ­¥å®Œæˆ%') AS success_count,
    COUNTIF(severity = 'ERROR') AS error_count,
    COUNT(*) AS total_attempts
  FROM `wprojectl.run_googleapis_com_requests`
  WHERE resource.labels.service_name = 'data-sync-service'
    AND timestamp >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 24 HOUR)
  GROUP BY hour
)
SELECT 
  hour,
  success_count,
  error_count,
  total_attempts,
  ROUND(success_count * 100.0 / NULLIF(total_attempts, 0), 2) AS success_rate,
  CASE 
    WHEN success_count * 100.0 / NULLIF(total_attempts, 0) >= 99.5 THEN 'ğŸŸ¢ ä¼˜ç§€'
    WHEN success_count * 100.0 / NULLIF(total_attempts, 0) >= 95.0 THEN 'ğŸŸ¡ è‰¯å¥½'
    ELSE 'ğŸ”´ å¼‚å¸¸'
  END AS status
FROM sync_attempts
ORDER BY hour DESC;
```

### 4.2 å‘Šè­¦è§„åˆ™å¢å¼º

**æ›´æ–°freshness-alert-checkeræœåŠ¡**:

```python
# åœ¨ freshness-alert-checker/main.py ä¸­æ·»åŠ 

def check_scheduler_execution():
    """æ£€æŸ¥Cloud Scheduleræ‰§è¡ŒçŠ¶æ€"""
    query = """
    SELECT status_code, status_desc, last_attempt_time
    FROM `wprojectl.pc28_monitor.scheduler_execution_v`
    LIMIT 1
    """
    
    results = client.query(query).result()
    alerts = []
    
    for row in results:
        if row.status_code != '0':
            alerts.append({
                "priority": "P0",
                "message": f"data-sync-jobæ‰§è¡Œå¤±è´¥: {row.status_desc} (çŠ¶æ€ç : {row.status_code})"
            })
        
        # æ£€æŸ¥æœ€åæ‰§è¡Œæ—¶é—´
        lag_minutes = (datetime.now() - row.last_attempt_time).total_seconds() / 60
        if lag_minutes > 10:
            alerts.append({
                "priority": "P1",
                "message": f"data-sync-jobé•¿æ—¶é—´æœªæ‰§è¡Œ: {lag_minutes:.0f}åˆ†é’Ÿ"
            })
    
    return alerts

def check_sync_success_rate():
    """æ£€æŸ¥åŒæ­¥æˆåŠŸç‡"""
    query = """
    SELECT success_rate, status, hour
    FROM `wprojectl.pc28_monitor.sync_success_rate_v`
    ORDER BY hour DESC
    LIMIT 1
    """
    
    results = client.query(query).result()
    alerts = []
    
    for row in results:
        if row.success_rate < 95.0:
            alerts.append({
                "priority": "P1",
                "message": f"æ•°æ®åŒæ­¥æˆåŠŸç‡ä½: {row.success_rate:.2f}% (<95%)"
            })
        elif row.success_rate < 99.5:
            alerts.append({
                "priority": "P2",
                "message": f"æ•°æ®åŒæ­¥æˆåŠŸç‡åä½: {row.success_rate:.2f}% (<99.5%)"
            })
    
    return alerts

@app.route('/check', methods=['POST'])
def check():
    """æ‰§è¡Œå®Œæ•´æ£€æŸ¥ï¼ˆå¢å¼ºç‰ˆï¼‰"""
    all_alerts = []
    
    # åŸæœ‰æ£€æŸ¥
    all_alerts.extend(check_freshness())
    all_alerts.extend(check_quality())
    all_alerts.extend(check_latency())
    
    # æ–°å¢æ£€æŸ¥
    all_alerts.extend(check_scheduler_execution())
    all_alerts.extend(check_sync_success_rate())
    
    # å‘é€å‘Šè­¦
    if all_alerts:
        for alert in all_alerts:
            send_telegram(alert["message"], alert["priority"])
    
    return jsonify({
        "status": "success",
        "alerts_count": len(all_alerts),
        "alerts": all_alerts
    })
```

---

## ğŸ“š é˜¶æ®µ5ï¼šæ–‡æ¡£ä¸è§„èŒƒå»ºç«‹ï¼ˆ20åˆ†é’Ÿï¼‰

### 5.1 è¿ç»´æ‰‹å†Œ

**åˆ›å»ºæ•°æ®æµè½¬è¿ç»´æ‰‹å†Œ**:
```markdown
# æ•°æ®æµè½¬è¿ç»´æ‰‹å†Œ

## æ—¥å¸¸å·¡æ£€æ¸…å•

æ¯æ—¥å·¡æ£€ï¼ˆè‡ªåŠ¨åŒ–ï¼‰:
  âœ… æ•°æ®æ–°é²œåº¦æ£€æŸ¥
  âœ… åŒæ­¥æˆåŠŸç‡æ£€æŸ¥
  âœ… Scheduleræ‰§è¡ŒçŠ¶æ€
  âœ… æ•°æ®å®Œæ•´æ€§éªŒè¯

æ¯å‘¨å·¡æ£€ï¼ˆäººå·¥ï¼‰:
  âœ… åˆ†åŒºè¡¨æ€§èƒ½å®¡è®¡
  âœ… æŸ¥è¯¢æˆæœ¬åˆ†æ
  âœ… å­˜å‚¨ç©ºé—´ä¼˜åŒ–
  âœ… å‘Šè­¦è¯¯æŠ¥ç‡åˆ†æ

æ¯æœˆå·¡æ£€ï¼ˆäººå·¥ï¼‰:
  âœ… æ•°æ®æµè½¬æ¶æ„review
  âœ… SLOè¾¾æˆç‡åˆ†æ
  âœ… æ€§èƒ½ä¼˜åŒ–å»ºè®®
  âœ… æˆæœ¬ä¼˜åŒ–å»ºè®®

## æ•…éšœå¤„ç†æµç¨‹

1. æ•°æ®åŒæ­¥ä¸­æ–­
   - æ£€æŸ¥Cloud SchedulerçŠ¶æ€
   - æ£€æŸ¥OIDCè®¤è¯é…ç½®
   - æ£€æŸ¥æœåŠ¡è´¦å·æƒé™
   - æ‰‹åŠ¨è§¦å‘æµ‹è¯•
   - æŸ¥çœ‹æœåŠ¡æ—¥å¿—

2. æ•°æ®å»¶è¿Ÿè¿‡é«˜
   - æ£€æŸ¥æºè¡¨æ–°é²œåº¦
   - æ£€æŸ¥åŒæ­¥æœåŠ¡æ€§èƒ½
   - æ£€æŸ¥BigQueryä½œä¸šé˜Ÿåˆ—
   - ä¼˜åŒ–åŒæ­¥ç­–ç•¥

3. æ•°æ®ç¼ºå¤±
   - ç¡®å®šç¼ºå¤±èŒƒå›´
   - ä»æºè¡¨æ‰‹åŠ¨åŒæ­¥
   - åˆ†ææ ¹å› 
   - ä¿®å¤æœºåˆ¶
   - é¢„é˜²æªæ–½

## ç´§æ€¥è”ç³»

P0æ•…éšœ: ç«‹å³é€šçŸ¥
P1æ•…éšœ: 15åˆ†é’Ÿå†…é€šçŸ¥
P2æ•…éšœ: æ¯æ—¥æ±‡æ€»
```

### 5.2 æ›´æ–°è§„åˆ™æ–‡æ¡£

**æ›´æ–°PROMPT_OWASP_V2.md**:

æ–°å¢æ•™è®­4å’Œ5ï¼ˆå·²åœ¨DATA_FLOW_ISSUE_ANALYSIS.mdä¸­å®šä¹‰ï¼‰

---

## ğŸ“Š æˆæœ¬ä¸æ”¶ç›Šåˆ†æ

### æŠ•å…¥æˆæœ¬

```yaml
è®¡ç®—æˆæœ¬:
  - data-sync-service: $0.50/æœˆ (æ¯5åˆ†é’Ÿ)
  - feature-engineering-service: $1.00/æœˆ (æ¯10åˆ†é’Ÿ)
  
BigQueryæˆæœ¬:
  - æŸ¥è¯¢æˆæœ¬: $2.00/æœˆ â†’ $0.50/æœˆ (-75%)
  - å­˜å‚¨æˆæœ¬: $5.00/æœˆ â†’ $3.50/æœˆ (-30%)
  
å¼€å‘æˆæœ¬:
  - ä¸€æ¬¡æ€§å¼€å‘: 4å°æ—¶
  - ç»´æŠ¤æˆæœ¬: 1å°æ—¶/æœˆ
  
æ€»æˆæœ¬:
  - é¦–æœˆ: $6.50 (å«å¼€å‘)
  - åç»­: $5.00/æœˆ
```

### æ”¶ç›Š

```yaml
æ€§èƒ½æå‡:
  - æŸ¥è¯¢å»¶è¿Ÿ: -70%
  - åŒæ­¥å»¶è¿Ÿ: -80%
  - ç«¯åˆ°ç«¯å»¶è¿Ÿ: -60%

å¯é æ€§æå‡:
  - åŒæ­¥æˆåŠŸç‡: 90% â†’ 99.9%
  - MTTR: 9å°æ—¶ â†’ 5åˆ†é’Ÿ (-98%)
  - è‡ªåŠ¨æ¢å¤: 0% â†’ 100%

æˆæœ¬èŠ‚çœ:
  - BigQueryæŸ¥è¯¢: -75%
  - BigQueryå­˜å‚¨: -30%
  - äººå·¥è¿ç»´: -90%

ROI:
  - é¦–æœˆ: 10å€
  - é•¿æœŸ: 50å€+
```

---

## ğŸ¯ æ‰§è¡Œè®¡åˆ’

### ç«‹å³æ‰§è¡Œï¼ˆä»Šæ™šï¼‰

**é˜¶æ®µ1: P0ç´§æ€¥ä¿®å¤**ï¼ˆ40åˆ†é’Ÿï¼‰
- [ ] æ‰‹åŠ¨åŒæ­¥16æœŸç¼ºå¤±æ•°æ®
- [ ] ä¿®å¤data-sync-service OIDCè®¤è¯
- [ ] éªŒè¯ä¿®å¤æ•ˆæœ
- [ ] ç”Ÿæˆä¿®å¤æŠ¥å‘Š

### æ˜å¤©æ‰§è¡Œ

**é˜¶æ®µ2: æ•°æ®æµè½¬æ¶æ„ä¼˜åŒ–**ï¼ˆ60åˆ†é’Ÿï¼‰
- [ ] åˆ›å»ºåˆ†åŒºè¡¨
- [ ] ä¼˜åŒ–data-sync-serviceï¼ˆå¢é‡åŒæ­¥ï¼‰
- [ ] åˆ›å»ºfeature-engineering-service
- [ ] éƒ¨ç½²å¹¶æµ‹è¯•

**é˜¶æ®µ3: æ€§èƒ½ä¸å¯é æ€§æå‡**ï¼ˆ60åˆ†é’Ÿï¼‰
- [ ] åˆ›å»ºç‰©åŒ–è§†å›¾
- [ ] å®æ–½è‡ªåŠ¨æ•…éšœæ¢å¤
- [ ] å¢å¼ºå¥åº·æ£€æŸ¥
- [ ] æ€§èƒ½æµ‹è¯•éªŒè¯

### æœ¬å‘¨å†…æ‰§è¡Œ

**é˜¶æ®µ4: ç›‘æ§ä¸å‘Šè­¦å®Œå–„**ï¼ˆ40åˆ†é’Ÿï¼‰
- [ ] åˆ›å»ºæ‰§è¡Œå±‚ç›‘æ§è§†å›¾
- [ ] æ›´æ–°freshness-alert-checker
- [ ] æµ‹è¯•æ–°å‘Šè­¦è§„åˆ™
- [ ] 24å°æ—¶è§‚å¯ŸéªŒè¯

**é˜¶æ®µ5: æ–‡æ¡£ä¸è§„èŒƒå»ºç«‹**ï¼ˆ20åˆ†é’Ÿï¼‰
- [ ] ç¼–å†™è¿ç»´æ‰‹å†Œ
- [ ] æ›´æ–°PROMPT_OWASP_V2.md
- [ ] ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
- [ ] çŸ¥è¯†åˆ†äº«

---

## ğŸ“ éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶

```yaml
âœ… æ•°æ®åŒæ­¥:
  - å»¶è¿Ÿ â‰¤5åˆ†é’Ÿ (p95)
  - æˆåŠŸç‡ â‰¥99.9%
  - è‡ªåŠ¨æ¢å¤ â‰¤5åˆ†é’Ÿ

âœ… æ€§èƒ½:
  - æŸ¥è¯¢å“åº” â‰¤3ç§’
  - åŒæ­¥åå â‰¥100æœŸ/æ‰¹æ¬¡
  - èµ„æºåˆ©ç”¨ç‡ â‰¤70%

âœ… ç›‘æ§:
  - è¦†ç›–ç‡ 100%
  - å‘Šè­¦å»¶è¿Ÿ â‰¤1åˆ†é’Ÿ
  - è¯¯æŠ¥ç‡ â‰¤5%
```

### æ–‡æ¡£éªŒæ”¶

```yaml
âœ… è¿ç»´æ‰‹å†Œå®Œæ•´
âœ… æ•…éšœå¤„ç†æµç¨‹æ¸…æ™°
âœ… ç›‘æ§æŒ‡æ ‡å®šä¹‰æ˜ç¡®
âœ… ç´§æ€¥è”ç³»æ–¹å¼æ›´æ–°
```

---

**åˆ¶å®šå®Œæˆï¼ç­‰å¾…æ‚¨çš„æ‰¹å‡†æ‰§è¡Œã€‚**

**å»ºè®®ï¼šç«‹å³æ‰§è¡Œé˜¶æ®µ1ï¼ˆP0ç´§æ€¥ä¿®å¤ï¼‰ï¼Œæ˜å¤©ç»§ç»­åç»­ä¼˜åŒ–ã€‚**

**cursor**



